{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import shutil\n",
    "\n",
    "# Download and extract segmentation dataset\n",
    "def download_and_extract_segmentation_dataset():\n",
    "    # Create directory for the dataset\n",
    "    os.makedirs(\"segmentation_data\", exist_ok=True)\n",
    "    \n",
    "    # Download MFSD dataset\n",
    "    url = \"https://github.com/sadjadrz/MFSD/archive/refs/heads/main.zip\"\n",
    "    print(\"Downloading face mask segmentation dataset...\")\n",
    "    r = requests.get(url, stream=True)\n",
    "    with zipfile.ZipFile(BytesIO(r.content)) as zip_ref:\n",
    "        zip_ref.extractall(\"./\")\n",
    "    \n",
    "    # Create directories for processed data\n",
    "    os.makedirs(\"segmentation_data/images\", exist_ok=True)\n",
    "    os.makedirs(\"segmentation_data/masks\", exist_ok=True)\n",
    "    \n",
    "    # Extract images and masks\n",
    "    source_dir = \"./MFSD-main/dataset\"\n",
    "    \n",
    "    # Copy files to our working directory\n",
    "    for filename in os.listdir(os.path.join(source_dir, \"images\")):\n",
    "        src_path = os.path.join(source_dir, \"images\", filename)\n",
    "        dst_path = os.path.join(\"segmentation_data/images\", filename)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    for filename in os.listdir(os.path.join(source_dir, \"masks\")):\n",
    "        src_path = os.path.join(source_dir, \"masks\", filename)\n",
    "        dst_path = os.path.join(\"segmentation_data/masks\", filename)\n",
    "        shutil.copy(src_path, dst_path)\n",
    "    \n",
    "    print(\"Segmentation dataset downloaded and extracted successfully.\")\n",
    "\n",
    "# Run the download function\n",
    "download_and_extract_segmentation_dataset()\n",
    "\n",
    "# Task 3: Traditional Segmentation Methods\n",
    "\n",
    "def load_segmentation_dataset(images_dir, masks_dir, limit=None):\n",
    "    \"\"\"Load segmentation dataset\"\"\"\n",
    "    images = []\n",
    "    masks = []\n",
    "    filenames = []\n",
    "    \n",
    "    # List all image files\n",
    "    image_files = os.listdir(images_dir)\n",
    "    if limit:\n",
    "        image_files = image_files[:limit]\n",
    "    \n",
    "    for filename in tqdm(image_files, desc=\"Loading segmentation dataset\"):\n",
    "        # Load image\n",
    "        img_path = os.path.join(images_dir, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Load corresponding mask\n",
    "        mask_path = os.path.join(masks_dir, filename)\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Apply threshold to create binary mask\n",
    "        _, mask = cv2.threshold(mask, 127, 255, cv2.THRESH_BINARY)\n",
    "        \n",
    "        # Resize for consistency\n",
    "        img = cv2.resize(img, (256, 256))\n",
    "        mask = cv2.resize(mask, (256, 256))\n",
    "        \n",
    "        images.append(img)\n",
    "        masks.append(mask)\n",
    "        filenames.append(filename)\n",
    "    \n",
    "    return np.array(images), np.array(masks), filenames\n",
    "\n",
    "# Load segmentation dataset\n",
    "images, ground_truth_masks, filenames = load_segmentation_dataset(\n",
    "    \"segmentation_data/images\", \n",
    "    \"segmentation_data/masks\",\n",
    "    limit=100  # Limit for faster processing during development\n",
    ")\n",
    "\n",
    "# Display some sample images and their masks\n",
    "def display_samples(images, masks, num_samples=3):\n",
    "    \"\"\"Display sample images and their masks\"\"\"\n",
    "    plt.figure(figsize=(15, 5 * num_samples))\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        # Original image\n",
    "        plt.subplot(num_samples, 3, i*3+1)\n",
    "        plt.imshow(images[i])\n",
    "        plt.title(f\"Original Image {i+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(num_samples, 3, i*3+2)\n",
    "        plt.imshow(masks[i], cmap='gray')\n",
    "        plt.title(f\"Ground Truth Mask {i+1}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Overlay mask on image\n",
    "        plt.subplot(num_samples, 3, i*3+3)\n",
    "        overlay = images[i].copy()\n",
    "        overlay[masks[i] > 0] = (255, 0, 0)  # Red overlay\n",
    "        plt.imshow(overlay)\n",
    "        plt.title(f\"Overlay {i+1}\")\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images and masks\n",
    "display_samples(images, ground_truth_masks)\n",
    "\n",
    "# Implement traditional segmentation methods\n",
    "\n",
    "def color_thresholding(image):\n",
    "    \"\"\"Segment mask using color thresholding\"\"\"\n",
    "    # Convert to HSV color space\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Define color range for face masks (typical blue/white masks)\n",
    "    lower_blue = np.array([90, 50, 50])\n",
    "    upper_blue = np.array([130, 255, 255])\n",
    "    lower_white = np.array([0, 0, 180])\n",
    "    upper_white = np.array([180, 30, 255])\n",
    "    \n",
    "    # Create masks\n",
    "    blue_mask = cv2.inRange(hsv, lower_blue, upper_blue)\n",
    "    white_mask = cv2.inRange(hsv, lower_white, upper_white)\n",
    "    \n",
    "    # Combine masks\n",
    "    combined_mask = cv2.bitwise_or(blue_mask, white_mask)\n",
    "    \n",
    "    # Apply morphological operations to clean up the mask\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel)\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return combined_mask\n",
    "\n",
    "def edge_based_segmentation(image):\n",
    "    \"\"\"Segment mask using edge detection and contour finding\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur\n",
    "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    \n",
    "    # Detect edges using Canny\n",
    "    edges = cv2.Canny(blurred, 50, 150)\n",
    "    \n",
    "    # Dilate the edges to connect gaps\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Find contours\n",
    "    contours, _ = cv2.findContours(dilated.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Create a mask from contours\n",
    "    mask = np.zeros_like(gray)\n",
    "    \n",
    "    # Filter contours based on area\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > 500:  # Filter out small contours\n",
    "            cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "    \n",
    "    # Apply morphological operations to clean up\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def region_growing(image, seed_points=None):\n",
    "    \"\"\"Segment mask using region growing algorithm\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # If no seed points provided, use the center of the image\n",
    "    if seed_points is None:\n",
    "        h, w = gray.shape\n",
    "        seed_points = [(w//2, h//2)]\n",
    "    \n",
    "    # Create mask\n",
    "    mask = np.zeros_like(gray)\n",
    "    \n",
    "    # Define region growing parameters\n",
    "    threshold = 10  # Intensity threshold\n",
    "    \n",
    "    # Process each seed point\n",
    "    for seed in seed_points:\n",
    "        x, y = seed\n",
    "        seed_value = gray[y, x]\n",
    "        \n",
    "        # Initialize queue with seed point\n",
    "        queue = [(x, y)]\n",
    "        processed = set([(x, y)])\n",
    "        \n",
    "        while queue:\n",
    "            curr_x, curr_y = queue.pop(0)\n",
    "            mask[curr_y, curr_x] = 255\n",
    "            \n",
    "            # Check 8-connected neighbors\n",
    "            neighbors = [\n",
    "                (curr_x+1, curr_y), (curr_x-1, curr_y),\n",
    "                (curr_x, curr_y+1), (curr_x, curr_y-1),\n",
    "                (curr_x+1, curr_y+1), (curr_x-1, curr_y-1),\n",
    "                (curr_x+1, curr_y-1), (curr_x-1, curr_y+1)\n",
    "            ]\n",
    "            \n",
    "            for nx, ny in neighbors:\n",
    "                # Check if within image bounds\n",
    "                if 0 <= nx < gray.shape[1] and 0 <= ny < gray.shape[0]:\n",
    "                    # Check if not processed and within threshold\n",
    "                    if (nx, ny) not in processed and abs(int(gray[ny, nx]) - int(seed_value)) < threshold:\n",
    "                        queue.append((nx, ny))\n",
    "                        processed.add((nx, ny))\n",
    "    \n",
    "    # Apply morphological operations to clean up\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def watershed_segmentation(image):\n",
    "    \"\"\"Segment mask using watershed algorithm\"\"\"\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply threshold\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # Noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    # Sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "    \n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)\n",
    "    \n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg, sure_fg)\n",
    "    \n",
    "    # Marker labelling\n",
    "    _, markers = cv2.connectedComponents(sure_fg)\n",
    "    \n",
    "    # Add one to all labels so that background is not 0, but 1\n",
    "    markers = markers + 1\n",
    "    \n",
    "    # Mark the unknown region with 0\n",
    "    markers[unknown == 255] = 0\n",
    "    \n",
    "    # Apply watershed\n",
    "    markers = cv2.watershed(image, markers)\n",
    "    \n",
    "    # Create mask: regions marked as 1 (background) are set to 0, others to 255\n",
    "    mask = np.zeros_like(gray)\n",
    "    mask[markers > 1] = 255\n",
    "    \n",
    "    # Clean up with morphological operations\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Apply traditional segmentation methods to dataset\n",
    "def apply_segmentation_methods(images):\n",
    "    \"\"\"Apply different segmentation methods to images\"\"\"\n",
    "    color_masks = []\n",
    "    edge_masks = []\n",
    "    watershed_masks = []\n",
    "    \n",
    "    for img in tqdm(images, desc=\"Applying segmentation methods\"):\n",
    "        color_masks.append(color_thresholding(img))\n",
    "        edge_masks.append(edge_based_segmentation(img))\n",
    "        watershed_masks.append(watershed_segmentation(img))\n",
    "    \n",
    "    return {\n",
    "        'Color Thresholding': np.array(color_masks),\n",
    "        'Edge-based': np.array(edge_masks),\n",
    "        'Watershed': np.array(watershed_masks)\n",
    "    }\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def calculate_metrics(pred_mask, gt_mask):\n",
    "    \"\"\"Calculate IoU and Dice score\"\"\"\n",
    "    # Convert to binary\n",
    "    pred_mask = (pred_mask > 0).astype(np.uint8)\n",
    "    gt_mask = (gt_mask > 0).astype(np.uint8)\n",
    "    \n",
    "    # Calculate intersection and union\n",
    "    intersection = np.logical_and(pred_mask, gt_mask).sum()\n",
    "    union = np.logical_or(pred_mask, gt_mask).sum()\n",
    "    \n",
    "    # Calculate IoU\n",
    "    iou = intersection / union if union > 0 else 0\n",
    "    \n",
    "    # Calculate Dice score\n",
    "    dice = (2 * intersection) / (pred_mask.sum() + gt_mask.sum()) if (pred_mask.sum() + gt_mask.sum()) > 0 else 0\n",
    "    \n",
    "    return iou, dice\n",
    "\n",
    "# Evaluate traditional segmentation methods\n",
    "def evaluate_segmentation_methods(segmented_masks, ground_truth_masks):\n",
    "    \"\"\"Evaluate traditional segmentation methods\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for method_name, pred_masks in segmented_masks.items():\n",
    "        ious = []\n",
    "        dice_scores = []\n",
    "        \n",
    "        for i in range(len(pred_masks)):\n",
    "            iou, dice = calculate_metrics(pred_masks[i], ground_truth_masks[i])\n",
    "            ious.append(iou)\n",
    "            dice_scores.append(dice)\n",
    "        \n",
    "        results[method_name] = {\n",
    "            'IoU': np.mean(ious),\n",
    "            'Dice': np.mean(dice_scores)\n",
    "        }\n",
    "        \n",
    "        print(f\"{method_name} - Average IoU: {np.mean(ious):.4f}, Average Dice: {np.mean(dice_scores):.4f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Display segmentation results\n",
    "def display_segmentation_results(images, ground_truth_masks, segmented_masks, indices, metrics):\n",
    "    \"\"\"Display segmentation results for selected images\"\"\"\n",
    "    methods = list(segmented_masks.keys())\n",
    "    num_methods = len(methods)\n",
    "    num_images = len(indices)\n",
    "    \n",
    "    plt.figure(figsize=(15, 5 * num_images))\n",
    "    \n",
    "    for idx, image_idx in enumerate(indices):\n",
    "        # Original image\n",
    "        plt.subplot(num_images, num_methods + 2, idx * (num_methods + 2) + 1)\n",
    "        plt.imshow(images[image_idx])\n",
    "        plt.title(f\"Original {image_idx}\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Ground truth mask\n",
    "        plt.subplot(num_images, num_methods + 2, idx * (num_methods + 2) + 2)\n",
    "        plt.imshow(ground_truth_masks[image_idx], cmap='gray')\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Segmentation results\n",
    "        for method_idx, method_name in enumerate(methods):\n",
    "            plt.subplot(num_images, num_methods + 2, idx * (num_methods + 2) + method_idx + 3)\n",
    "            plt.imshow(segmented_masks[method_name][image_idx], cmap='gray')\n",
    "            \n",
    "            # Calculate metrics for this specific image\n",
    "            iou, dice = calculate_metrics(segmented_masks[method_name][image_idx], ground_truth_masks[image_idx])\n",
    "            plt.title(f\"{method_name}\\nIoU: {iou:.2f}, Dice: {dice:.2f}\")\n",
    "            plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Overall performance comparison\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot IoU scores\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(metrics.keys(), [metrics[m]['IoU'] for m in metrics.keys()])\n",
    "    plt.title('Average IoU Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    # Plot Dice scores\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(metrics.keys(), [metrics[m]['Dice'] for m in metrics.keys()])\n",
    "    plt.title('Average Dice Score')\n",
    "    plt.ylim(0, 1)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply traditional segmentation methods\n",
    "segmented_masks = apply_segmentation_methods(images)\n",
    "\n",
    "# Evaluate methods\n",
    "metrics = evaluate_segmentation_methods(segmented_masks, ground_truth_masks)\n",
    "\n",
    "# Display results for a few sample images\n",
    "display_segmentation_results(images, ground_truth_masks, segmented_masks, [0, 1, 2], metrics)\n",
    "\n",
    "# Task 4: Mask Segmentation Using U-Net\n",
    "\n",
    "# Define U-Net model\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"Double convolution block for U-Net\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(DoubleConv, self).__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels=3, out_channels=1):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.enc1 = DoubleConv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = DoubleConv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = DoubleConv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.enc4 = DoubleConv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = DoubleConv(512, 1024)\n",
    "        \n",
    "        # Decoder (upsampling)\n",
    "        self.up_conv4 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.dec4 = DoubleConv(1024, 512)  # 512 + 512 = 1024 input channels after concat\n",
    "        \n",
    "        self.up_conv3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = DoubleConv(512, 256)  # 256 + 256 = 512 input channels after concat\n",
    "        \n",
    "        self.up_conv2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = DoubleConv(256, 128)  # 128 + 128 = 256 input channels after concat\n",
    "        \n",
    "        self.up_conv1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = DoubleConv(128, 64)  # 64 + 64 = 128 input channels after concat\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.enc1(x)\n",
    "        enc2 = self.enc2(self.pool1(enc1))\n",
    "        enc3 = self.enc3(self.pool2(enc2))\n",
    "        enc4 = self.enc4(self.pool3(enc3))\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(self.pool4(enc4))\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        dec4 = self.up_conv4(bottleneck)\n",
    "        dec4 = torch.cat([dec4, enc4], dim=1)\n",
    "        dec4 = self.dec4(dec4)\n",
    "        \n",
    "        dec3 = self.up_conv3(dec4)\n",
    "        dec3 = torch.cat([dec3, enc3], dim=1)\n",
    "        dec3 = self.dec3(dec3)\n",
    "        \n",
    "        dec2 = self.up_conv2(dec3)\n",
    "        dec2 = torch.cat([dec2, enc2], dim=1)\n",
    "        dec2 = self.dec2(dec2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
